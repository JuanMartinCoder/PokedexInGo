# WebCrawler

## What is a Web Crawler?

A web crawler, or spider, is a type of bot that is typically operated by search engines like Google and Bing. Their purpose is to index the content of websites all across the Internet so that those websites can appear in search engine results.

## What is the purpose of this project?

The purpose is to write a Golang CLI application that generates an "internal links" report for any website on the internet by crawling each page of the site.

## Learning Goals

- Practice writing a CLI application in Golang
- Practice making HTTP Requests in Go 
- Learn how to parse HTML with Go 
- Practice unit testing

## Techonologies Used

- [Go](https://golang.org/)
- [Go Modules](https://github.com/golang/go/wiki/Modules)
- [Go Testing](https://golang.org/pkg/testing/)
- [Go HTTP Client](https://golang.org/pkg/net/http/)
- [Go HTML Parser](https://golang.org/pkg/html/)
- TDD ( Test Driven Development )
